# ðŸ§  Body Fat Percentage Prediction using ML
An exploratory project on different scikit-learn regression models.
## ðŸ“Œ Project Overview
This project explores how different machine learning regression models can be used to predict body fat percentage based on physiological measurements.
The dataset comes from an ARFF file (`bodyfat.arff`), and the goal is to compare models and find the one that achieves the highest accuracy.

The main purpose of this project is to personally familiarise myself with data preparation, visualisation and machine learning with the `scikit-learn` library.

## ðŸ“‚ Repository Structure
```bash
bodyfat-ml/
â”‚
â”œâ”€â”€ data/                 # Raw and preprocessed datasets
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ bodyfat.arff
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ X_test_all_features.csv
â”‚   â”‚   â”œâ”€â”€ X_test_top_features.csv
â”‚   â”‚   â”œâ”€â”€ X_train_all_features.csv
â”‚   â”‚   â”œâ”€â”€ X_train_top_features.csv
â”‚   â”‚   â”œâ”€â”€ y_test.csv
â”‚   â”‚   â””â”€â”€ y_train.csv
â”‚   â”‚
â”‚   â””â”€â”€ README.md
â”‚ 
â”œâ”€â”€ notebooks/            # Jupyter Notebooks (Kaggle-friendly)
â”‚   â”œâ”€â”€ 01_exploration.ipynb   # Data loading & EDA
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb # Cleaning, splitting, scaling
â”‚   â”œâ”€â”€ 03_models.ipynb        # Training multiple regressors
â”‚   â””â”€â”€ 04_results.ipynb       # Evaluation, visualisation and final model
â”‚
â”œâ”€â”€ objects/               # Saved scaler, selector, and pipelines (if any)
â”‚   â”œâ”€â”€ scaler.pkl        
â”‚   â””â”€â”€ selector.pkl
â”‚
â”œâ”€â”€ models/               # Saved ML models
â”‚   â”œâ”€â”€ model_comparison.csv   # Metrics of all trained models
â”‚   â””â”€â”€ best_model.pkl
â”‚
â”œâ”€â”€ results/              # Outputs & predictions
â”‚   â””â”€â”€ predictions.csv
â”‚
â””â”€â”€ README.md             # Project documentation
```
## ðŸ”¬ Methodology

1. Exploration: Load dataset, check for missing values, visualise distributions & correlations.
2. Preprocessing: Clean data, train-test split, apply feature scaling.
3. Model Training: Train and evaluate multiple regression models:
    - Linear Regression
    - Decision Tree Regressor
    - Random Forest Regressor
    - Gradient Boosting Regressor
    - XGBoost Regressor
    - Ridge Regression
    - ElasticNet Regression
    - Support Vector Regression
    - K Nearest Neighbors Regression

4. Evaluation: Compare models using MAE, RMSE, and RÂ².
5. Results: Save the best model and visualise predictions vs. actual values.

## ðŸ“Š Results

Best model: Ridge

Performance metrics :
- MAE: `3.249`
- RMSE: `4.03`
- RÂ²: `0.651`

## ðŸš€ Future Work

- Try neural networks for regression.
- Explore feature selection to reduce dimensionality.
- Deploy best model as a web app (e.g., Streamlit).

## ðŸ‘¤ Author
Jan Manatunga â€“ Aspiring student passionate about ML & AI.


