{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12959692,"sourceType":"datasetVersion","datasetId":8201884},{"sourceId":259740067,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8446714a-ec4f-460e-b304-aa6b1daf6285","cell_type":"markdown","source":"# 03 — Modeling\n\n**Goal:** Train multiple regressors from preprocessed data and compare via cross-validated MAE/RMSE/R².\n\nIn this third notebook, we will be making use of the preprocessed data we have derived from our body fat dataset to train different machine learning regression models, measure their accuracy via different key metrics and store them for evaluation and visualisation in the next notebook\n\n**Checklist**\n- Linear models (LinearRegression/Ridge/Lasso/ElasticNet).\n- Tree ensembles (RandomForest, GradientBoosting, XGBoost).\n- Cross-validation with consistent splits & scoring.\n- Log metrics for each model.","metadata":{}},{"id":"d75fc24f-6d85-492c-9787-d8a94f04efe2","cell_type":"code","source":"# Imports\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nimport joblib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:03:42.213487Z","iopub.execute_input":"2025-09-04T11:03:42.213682Z","iopub.status.idle":"2025-09-04T11:03:44.346053Z","shell.execute_reply.started":"2025-09-04T11:03:42.213662Z","shell.execute_reply":"2025-09-04T11:03:44.345169Z"}},"outputs":[],"execution_count":1},{"id":"14ef14be-fb18-4095-a9a3-d18875101c39","cell_type":"markdown","source":"## Loading preprocessed data\n\nWe will be loading both the scaled-only and the scaled-and-feature-selected preprocessed datasets, which will then allow us to compare the performance of different models: whether they provide better predictions when trained on either of these datasets.","metadata":{}},{"id":"784feec5-b71b-4a54-ae10-99adf4cb9d8b","cell_type":"code","source":"# Scaled-only dataset\nX_train_scaled = pd.read_csv(\"/kaggle/input/preprocessed-bodyfat/X_train_all_features.csv\")\nX_test_scaled = pd.read_csv(\"/kaggle/input/preprocessed-bodyfat/X_test_all_features.csv\")\ny_train = pd.read_csv(\"/kaggle/input/preprocessed-bodyfat/y_train.csv\").values.ravel()\ny_test = pd.read_csv(\"/kaggle/input/preprocessed-bodyfat/y_test.csv\").values.ravel()\n\n# Feature-selected dataset\nX_train_fs = pd.read_csv('/kaggle/input/preprocessed-bodyfat/X_train_top_features.csv')\nX_test_fs = pd.read_csv('/kaggle/input/preprocessed-bodyfat/X_test_top_features.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:05:43.452941Z","iopub.execute_input":"2025-09-04T11:05:43.453910Z","iopub.status.idle":"2025-09-04T11:05:43.473798Z","shell.execute_reply.started":"2025-09-04T11:05:43.453882Z","shell.execute_reply":"2025-09-04T11:05:43.472981Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array([19.2, 19.2, 28. , 20.5, 16.7, 12.1, 23.6, 18.6, 11.7, 11.9, 26.1,\n       24.5, 14.8, 22.5,  6.3,  5.3, 22. , 20.9, 20.4, 14. , 14.9, 16.5,\n       13.9, 13.8, 21.3, 30.4, 23.6, 15. ,  7.1, 13. , 24.9,  9.6, 17.5,\n       18.4, 18.7,  3.7, 21.4, 16. , 16.6, 11.5, 13.8, 23.6, 31.2,  9.4,\n       13.9, 22.5, 29. , 21.5, 23.3,  9.9, 35.2])"},"metadata":{}}],"execution_count":4},{"id":"1e798d09-3f46-422e-a9d0-b95cec3367c6","cell_type":"code","source":"print(\"Scaled-only shape:\", X_train_scaled.shape)\nprint(\"Feature-selected shape:\", X_train_fs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:09:19.001133Z","iopub.execute_input":"2025-09-04T11:09:19.001496Z","iopub.status.idle":"2025-09-04T11:09:19.006882Z","shell.execute_reply.started":"2025-09-04T11:09:19.001471Z","shell.execute_reply":"2025-09-04T11:09:19.005984Z"}},"outputs":[{"name":"stdout","text":"Scaled-only shape: (201, 13)\nFeature-selected shape: (201, 10)\n","output_type":"stream"}],"execution_count":5},{"id":"24b37f0d-c41b-412b-8add-9d701a283734","cell_type":"markdown","source":"## Define the model-fitting and evaluation function\n\nThis function will be the common execution for all the models we will be training, and will include defining the model class, training and testing data, cross-validation, evaluating them on different metrics and storing them in a dataframe for further evaluation.","metadata":{}},{"id":"984c09e3-b6de-4a3d-9502-8e25f0ae53ce","cell_type":"code","source":"def evaluate_model(model, model_name, X_train, X_test, y_train, y_test, dataset_name):\n    # Training all models via CV and storing metrics in a pandas DataFrame\n    results = []\n\n    # Cross-validation (5-fold, R² score)\n    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n\n    # Fitting model with training set\n    model.fit(X_train, y_train)\n    y_preds = model.predict(X_test)\n\n    #Evaluate across different metrics\n    mae = mean_absolute_error(y_test, y_preds)\n    rmse = np.sqrt(mean_squared_error(y_test, y_preds))\n    r2 = r2_score(y_test, y_preds)\n\n    # Collect results\n    results = {\n        \"Dataset\": dataset_name,\n        \"Model\": model_name,\n        \"CV_R2_Mean\": np.mean(cv_scores),\n        \"CV_R2_Std\": np.std(cv_scores),\n        \"Test_MAE\": mae,\n        \"Test_RMSE\": rmse,\n        \"Test_R2\": r2\n    }\n    \n    return pd.DataFrame([results])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:38:46.839413Z","iopub.execute_input":"2025-09-04T11:38:46.840238Z","iopub.status.idle":"2025-09-04T11:38:46.846329Z","shell.execute_reply.started":"2025-09-04T11:38:46.840210Z","shell.execute_reply":"2025-09-04T11:38:46.845451Z"}},"outputs":[],"execution_count":30},{"id":"4e21c3b1-cc54-4c09-88db-5a5edcb264ad","cell_type":"code","source":"all_results = pd.DataFrame()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:38:47.400463Z","iopub.execute_input":"2025-09-04T11:38:47.401187Z","iopub.status.idle":"2025-09-04T11:38:47.405599Z","shell.execute_reply.started":"2025-09-04T11:38:47.401156Z","shell.execute_reply":"2025-09-04T11:38:47.404838Z"}},"outputs":[],"execution_count":31},{"id":"fd24b53b-cd1a-46e8-8b02-d547823f75fb","cell_type":"markdown","source":"# Training data on different models\n\nIn order to find which ML model fits best for our purposes and the data we have at hand, we will be going through different models one by one, fitting our training dataset into each of them, and using our validation and testing datasets to measure and compare the models' accuracies.","metadata":{}},{"id":"652ea801-3de2-45fc-9888-39c298674997","cell_type":"markdown","source":"### 1. Decision Trees ","metadata":{}},{"id":"b0adc2bf-f4cc-4bba-8744-32a5e20d2c81","cell_type":"code","source":"# Decision Tree\nall_results = pd.concat([\n    all_results,\n    evaluate_model(DecisionTreeRegressor(random_state=42), 'DecisionTree', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(DecisionTreeRegressor(random_state=42), 'DecisionTree', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:38:48.680355Z","iopub.execute_input":"2025-09-04T11:38:48.681013Z","iopub.status.idle":"2025-09-04T11:38:48.738920Z","shell.execute_reply.started":"2025-09-04T11:38:48.680983Z","shell.execute_reply":"2025-09-04T11:38:48.737998Z"}},"outputs":[],"execution_count":32},{"id":"ea860957-a86b-4dc5-93e8-83f59c8d91ec","cell_type":"code","source":"all_results = all_results.reset_index(drop=True)\ndisplay(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:38:50.989182Z","iopub.execute_input":"2025-09-04T11:38:50.989507Z","iopub.status.idle":"2025-09-04T11:38:51.000089Z","shell.execute_reply.started":"2025-09-04T11:38:50.989472Z","shell.execute_reply":"2025-09-04T11:38:50.999097Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset         Model  CV_R2_Mean  CV_R2_Std  Test_MAE  Test_RMSE  \\\n0       Scaled-only  DecisionTree    0.425027   0.109527  4.270588   5.545463   \n1  Feature-Selected  DecisionTree    0.297680   0.115825  4.360784   5.549810   \n\n    Test_R2  \n0  0.338920  \n1  0.337883  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"id":"73c0f1fd-916e-4853-9a07-edb04c0f2435","cell_type":"markdown","source":"We have now generated a pandas DataFrame that stores all the metrics of our Decision Tree model on both the scaled-only and the scaled-and-feature-selected datasets. We will be appending the same dataframe as we train other models and store their results.\n\nAt a glance, we can see that the model didn't perform quite well, with the MAE score, for example, being around 4% (meaning that the model has an average error spanning about 4% body fat, and according to this context, there is quite a big room for error). As between the two datasets, based on the test metric scores, there does not seem to be much difference between the two (which is expected, as tree models are robust against features with less correlation, and don't affect them when training and making predictions)","metadata":{}},{"id":"220ba147-1a5b-4ff8-ab57-36ad2069f788","cell_type":"markdown","source":"### 2. Linear Regression","metadata":{}},{"id":"f328f736-9c9e-46f9-ab1d-43ce2274e4aa","cell_type":"code","source":"all_results = pd.concat([\n    all_results,\n    evaluate_model(LinearRegression(), 'LinearRegression', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(LinearRegression(), 'LinearRegression', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:46:39.714950Z","iopub.execute_input":"2025-09-04T11:46:39.715914Z","iopub.status.idle":"2025-09-04T11:46:39.781341Z","shell.execute_reply.started":"2025-09-04T11:46:39.715881Z","shell.execute_reply":"2025-09-04T11:46:39.780521Z"}},"outputs":[],"execution_count":34},{"id":"281d20cf-8036-4c60-a64b-87a05996dbf1","cell_type":"code","source":"display(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T11:46:49.675111Z","iopub.execute_input":"2025-09-04T11:46:49.675912Z","iopub.status.idle":"2025-09-04T11:46:49.686380Z","shell.execute_reply.started":"2025-09-04T11:46:49.675885Z","shell.execute_reply":"2025-09-04T11:46:49.685593Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0       Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1  Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n0       Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n0  Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n\n   Test_RMSE   Test_R2  \n0   5.545463  0.338920  \n1   5.549810  0.337883  \n0   4.240279  0.613484  \n0   4.029500  0.650956  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"id":"b41f438d-e1e2-47d9-9d49-f0eb77b6a75f","cell_type":"markdown","source":"Straight away, we can see a substantial improvement in our predictions when we switch to a Linear Regression model. The R² score has gone from 0.3 to 0.6, and the MAE and RMSE scores have gone down by 1% body fat (which, although it may not sound like much, is still quite an improvement). \n\nAs for the the results between the two datasets, the different is a bit more noticeable this time (with feature-selected performing subtly better).","metadata":{}},{"id":"e29f94c7-a043-4934-9651-b150825acbf5","cell_type":"markdown","source":"### 3. Random Forest Regressor","metadata":{}},{"id":"dcc80609-a19f-4f8b-9f23-44709a113ce1","cell_type":"code","source":"all_results = pd.concat([\n    all_results,\n    evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), 'RandomForest', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(RandomForestRegressor(n_estimators=100, random_state=42), 'RandomForest', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:00:02.126581Z","iopub.execute_input":"2025-09-04T12:00:02.127573Z","iopub.status.idle":"2025-09-04T12:00:04.263048Z","shell.execute_reply.started":"2025-09-04T12:00:02.127530Z","shell.execute_reply":"2025-09-04T12:00:04.262319Z"}},"outputs":[],"execution_count":36},{"id":"ec6ff930-bec0-47f9-b017-e9048166721d","cell_type":"code","source":"display(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:00:15.498599Z","iopub.execute_input":"2025-09-04T12:00:15.498951Z","iopub.status.idle":"2025-09-04T12:00:15.509990Z","shell.execute_reply.started":"2025-09-04T12:00:15.498927Z","shell.execute_reply":"2025-09-04T12:00:15.509257Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0       Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1  Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n0       Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n0  Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n0       Scaled-only      RandomForest    0.666268   0.054562  3.401824   \n0  Feature-Selected      RandomForest    0.655445   0.047001  3.328765   \n\n   Test_RMSE   Test_R2  \n0   5.545463  0.338920  \n1   5.549810  0.337883  \n0   4.240279  0.613484  \n0   4.029500  0.650956  \n0   4.097010  0.639162  \n0   3.984024  0.658790  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>RandomForest</td>\n      <td>0.666268</td>\n      <td>0.054562</td>\n      <td>3.401824</td>\n      <td>4.097010</td>\n      <td>0.639162</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>RandomForest</td>\n      <td>0.655445</td>\n      <td>0.047001</td>\n      <td>3.328765</td>\n      <td>3.984024</td>\n      <td>0.658790</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":37},{"id":"b8fb159b-257e-4648-bee1-1c881bcb36fc","cell_type":"markdown","source":"Now, comparing these models, the Random Forest and the Linear Regression models seem to be going neck-and-neck, as all their metric scores are quite close to each other, with some of them slightly edged by one or the other.\n\nRegarding the two datasets, even in this Random Forest model, the model trained on the feature-selected data performed slighlty better than the scaled-only data.","metadata":{}},{"id":"c6c25267-2f2d-46ed-99bb-5785a963eccb","cell_type":"markdown","source":"### 4. Gradient Boosting","metadata":{}},{"id":"8d1cd934-8231-477a-8b4e-3434fd19397e","cell_type":"code","source":"all_results = pd.concat([\n    all_results,\n    evaluate_model(GradientBoostingRegressor(n_estimators=100, random_state=42), 'GradientBoosting', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(GradientBoostingRegressor(n_estimators=100, random_state=42), 'GradientBoosting', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:07:42.096400Z","iopub.execute_input":"2025-09-04T12:07:42.096772Z","iopub.status.idle":"2025-09-04T12:07:43.022628Z","shell.execute_reply.started":"2025-09-04T12:07:42.096712Z","shell.execute_reply":"2025-09-04T12:07:43.021894Z"}},"outputs":[],"execution_count":38},{"id":"1beda89e-860e-492e-99fc-398330e7ef8d","cell_type":"code","source":"display(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:07:52.624437Z","iopub.execute_input":"2025-09-04T12:07:52.625020Z","iopub.status.idle":"2025-09-04T12:07:52.635431Z","shell.execute_reply.started":"2025-09-04T12:07:52.624993Z","shell.execute_reply":"2025-09-04T12:07:52.634615Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0       Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1  Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n0       Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n0  Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n0       Scaled-only      RandomForest    0.666268   0.054562  3.401824   \n0  Feature-Selected      RandomForest    0.655445   0.047001  3.328765   \n0       Scaled-only  GradientBoosting    0.625801   0.083593  3.308267   \n0  Feature-Selected  GradientBoosting    0.600088   0.077933  3.501641   \n\n   Test_RMSE   Test_R2  \n0   5.545463  0.338920  \n1   5.549810  0.337883  \n0   4.240279  0.613484  \n0   4.029500  0.650956  \n0   4.097010  0.639162  \n0   3.984024  0.658790  \n0   4.061587  0.645375  \n0   4.396792  0.584424  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>RandomForest</td>\n      <td>0.666268</td>\n      <td>0.054562</td>\n      <td>3.401824</td>\n      <td>4.097010</td>\n      <td>0.639162</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>RandomForest</td>\n      <td>0.655445</td>\n      <td>0.047001</td>\n      <td>3.328765</td>\n      <td>3.984024</td>\n      <td>0.658790</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>GradientBoosting</td>\n      <td>0.625801</td>\n      <td>0.083593</td>\n      <td>3.308267</td>\n      <td>4.061587</td>\n      <td>0.645375</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>GradientBoosting</td>\n      <td>0.600088</td>\n      <td>0.077933</td>\n      <td>3.501641</td>\n      <td>4.396792</td>\n      <td>0.584424</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"id":"640fae66-d1e2-4506-8cc4-1cadce889468","cell_type":"markdown","source":"Though almost at the same level as the previous two models, the Gradient Boosting model is an interesting case in this scenario. This model performed much better with the scaled-only data rather than the feature-selected data, and in comparison with the other models, the model that was trained in the former dataset performed better than the other models trained on the same dataset, but it felt a bit short against the other models which were trained on the feature-selected data.","metadata":{}},{"id":"5e0b8039-fd5b-462f-b7ab-edd9d03d7cfb","cell_type":"markdown","source":"### 5. XGBoost","metadata":{}},{"id":"d845b4a8-7600-4498-8183-e756e17a747b","cell_type":"code","source":"all_results = pd.concat([\n    all_results,\n    evaluate_model(XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42, verbosity=0), 'XGBoost', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42, verbosity=0), 'XGBoost', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:20:23.720269Z","iopub.execute_input":"2025-09-04T12:20:23.720558Z","iopub.status.idle":"2025-09-04T12:20:24.648889Z","shell.execute_reply.started":"2025-09-04T12:20:23.720537Z","shell.execute_reply":"2025-09-04T12:20:24.648221Z"}},"outputs":[],"execution_count":41},{"id":"c449d9bf-f932-40f6-b9bd-57605c15289a","cell_type":"code","source":"display(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:20:33.215801Z","iopub.execute_input":"2025-09-04T12:20:33.216118Z","iopub.status.idle":"2025-09-04T12:20:33.228083Z","shell.execute_reply.started":"2025-09-04T12:20:33.216080Z","shell.execute_reply":"2025-09-04T12:20:33.227294Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0       Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1  Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n0       Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n0  Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n0       Scaled-only      RandomForest    0.666268   0.054562  3.401824   \n0  Feature-Selected      RandomForest    0.655445   0.047001  3.328765   \n0       Scaled-only  GradientBoosting    0.625801   0.083593  3.308267   \n0  Feature-Selected  GradientBoosting    0.600088   0.077933  3.501641   \n0       Scaled-only           XGBoost    0.630576   0.074766  3.329362   \n0  Feature-Selected           XGBoost    0.587623   0.085667  3.304916   \n\n   Test_RMSE   Test_R2  \n0   5.545463  0.338920  \n1   5.549810  0.337883  \n0   4.240279  0.613484  \n0   4.029500  0.650956  \n0   4.097010  0.639162  \n0   3.984024  0.658790  \n0   4.061587  0.645375  \n0   4.396792  0.584424  \n0   4.112081  0.636502  \n0   4.203455  0.620168  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>RandomForest</td>\n      <td>0.666268</td>\n      <td>0.054562</td>\n      <td>3.401824</td>\n      <td>4.097010</td>\n      <td>0.639162</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>RandomForest</td>\n      <td>0.655445</td>\n      <td>0.047001</td>\n      <td>3.328765</td>\n      <td>3.984024</td>\n      <td>0.658790</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>GradientBoosting</td>\n      <td>0.625801</td>\n      <td>0.083593</td>\n      <td>3.308267</td>\n      <td>4.061587</td>\n      <td>0.645375</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>GradientBoosting</td>\n      <td>0.600088</td>\n      <td>0.077933</td>\n      <td>3.501641</td>\n      <td>4.396792</td>\n      <td>0.584424</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>XGBoost</td>\n      <td>0.630576</td>\n      <td>0.074766</td>\n      <td>3.329362</td>\n      <td>4.112081</td>\n      <td>0.636502</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>XGBoost</td>\n      <td>0.587623</td>\n      <td>0.085667</td>\n      <td>3.304916</td>\n      <td>4.203455</td>\n      <td>0.620168</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":42},{"id":"dca42394-b178-47a7-8182-35d7ed5179c6","cell_type":"markdown","source":"The XGBoost model performed quite similarly to the other models, and we can consider it as one of the better-performing ones from all the models we have trained thus far, although it isn't the top pick according to any of the metrics either.","metadata":{}},{"id":"f8f838d9-0ec3-4143-866c-4507101043d7","cell_type":"markdown","source":"### 6. Ridge","metadata":{}},{"id":"e59a1def-5f9f-4d77-ad82-8cf0e7b8d65c","cell_type":"code","source":"all_results = pd.concat([\n    all_results,\n    evaluate_model(Ridge(alpha=1.0), 'Ridge', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(Ridge(alpha=1.0), 'Ridge', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:28:53.837612Z","iopub.execute_input":"2025-09-04T12:28:53.838565Z","iopub.status.idle":"2025-09-04T12:28:53.894459Z","shell.execute_reply.started":"2025-09-04T12:28:53.838508Z","shell.execute_reply":"2025-09-04T12:28:53.893633Z"}},"outputs":[],"execution_count":43},{"id":"396fd2d8-6f1d-44ff-b83a-c18ee65e7fdb","cell_type":"code","source":"display(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:29:12.303947Z","iopub.execute_input":"2025-09-04T12:29:12.304481Z","iopub.status.idle":"2025-09-04T12:29:12.315879Z","shell.execute_reply.started":"2025-09-04T12:29:12.304452Z","shell.execute_reply":"2025-09-04T12:29:12.315152Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0       Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1  Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n0       Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n0  Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n0       Scaled-only      RandomForest    0.666268   0.054562  3.401824   \n0  Feature-Selected      RandomForest    0.655445   0.047001  3.328765   \n0       Scaled-only  GradientBoosting    0.625801   0.083593  3.308267   \n0  Feature-Selected  GradientBoosting    0.600088   0.077933  3.501641   \n0       Scaled-only           XGBoost    0.630576   0.074766  3.329362   \n0  Feature-Selected           XGBoost    0.587623   0.085667  3.304916   \n0       Scaled-only             Ridge    0.689364   0.031347  3.329175   \n0  Feature-Selected             Ridge    0.698422   0.029387  3.259923   \n\n   Test_RMSE   Test_R2  \n0   5.545463  0.338920  \n1   5.549810  0.337883  \n0   4.240279  0.613484  \n0   4.029500  0.650956  \n0   4.097010  0.639162  \n0   3.984024  0.658790  \n0   4.061587  0.645375  \n0   4.396792  0.584424  \n0   4.112081  0.636502  \n0   4.203455  0.620168  \n0   4.261240  0.609653  \n0   4.043927  0.648452  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>RandomForest</td>\n      <td>0.666268</td>\n      <td>0.054562</td>\n      <td>3.401824</td>\n      <td>4.097010</td>\n      <td>0.639162</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>RandomForest</td>\n      <td>0.655445</td>\n      <td>0.047001</td>\n      <td>3.328765</td>\n      <td>3.984024</td>\n      <td>0.658790</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>GradientBoosting</td>\n      <td>0.625801</td>\n      <td>0.083593</td>\n      <td>3.308267</td>\n      <td>4.061587</td>\n      <td>0.645375</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>GradientBoosting</td>\n      <td>0.600088</td>\n      <td>0.077933</td>\n      <td>3.501641</td>\n      <td>4.396792</td>\n      <td>0.584424</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>XGBoost</td>\n      <td>0.630576</td>\n      <td>0.074766</td>\n      <td>3.329362</td>\n      <td>4.112081</td>\n      <td>0.636502</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>XGBoost</td>\n      <td>0.587623</td>\n      <td>0.085667</td>\n      <td>3.304916</td>\n      <td>4.203455</td>\n      <td>0.620168</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>Ridge</td>\n      <td>0.689364</td>\n      <td>0.031347</td>\n      <td>3.329175</td>\n      <td>4.261240</td>\n      <td>0.609653</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>Ridge</td>\n      <td>0.698422</td>\n      <td>0.029387</td>\n      <td>3.259923</td>\n      <td>4.043927</td>\n      <td>0.648452</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"id":"06606eb9-3817-4a47-ac16-c95a23e79289","cell_type":"markdown","source":"Now, Ridge can be considered a good model at a glance, relative to our other models. The MAE score of the Ridge model that was trained on the feature-selected data is almost close to beating the score of the Linear Regression model (which is the first in this category in our collected results), and this model is also close to topping the leading models: Linear Regression and Random Forest, when it comes to the R² score.","metadata":{}},{"id":"3da23dfd-87dc-4396-86b7-27077e8097dc","cell_type":"markdown","source":"### 7. ElasticNet","metadata":{}},{"id":"aab49ae2-b33c-4e93-a5bf-68f5f580eb03","cell_type":"code","source":"all_results = pd.concat([\n    all_results,\n    evaluate_model(ElasticNet(alpha=1.0), 'ElasticNet', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(ElasticNet(alpha=1.0), 'ElasticNet', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:36:47.936432Z","iopub.execute_input":"2025-09-04T12:36:47.936811Z","iopub.status.idle":"2025-09-04T12:36:47.989710Z","shell.execute_reply.started":"2025-09-04T12:36:47.936780Z","shell.execute_reply":"2025-09-04T12:36:47.989163Z"}},"outputs":[],"execution_count":45},{"id":"27c51aee-8fef-4a04-8170-29b8e715671b","cell_type":"code","source":"display(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:36:55.440933Z","iopub.execute_input":"2025-09-04T12:36:55.441455Z","iopub.status.idle":"2025-09-04T12:36:55.453544Z","shell.execute_reply.started":"2025-09-04T12:36:55.441427Z","shell.execute_reply":"2025-09-04T12:36:55.452721Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0       Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1  Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n0       Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n0  Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n0       Scaled-only      RandomForest    0.666268   0.054562  3.401824   \n0  Feature-Selected      RandomForest    0.655445   0.047001  3.328765   \n0       Scaled-only  GradientBoosting    0.625801   0.083593  3.308267   \n0  Feature-Selected  GradientBoosting    0.600088   0.077933  3.501641   \n0       Scaled-only           XGBoost    0.630576   0.074766  3.329362   \n0  Feature-Selected           XGBoost    0.587623   0.085667  3.304916   \n0       Scaled-only             Ridge    0.689364   0.031347  3.329175   \n0  Feature-Selected             Ridge    0.698422   0.029387  3.259923   \n0       Scaled-only        ElasticNet    0.605416   0.057165  4.075815   \n0  Feature-Selected        ElasticNet    0.570783   0.053047  4.120743   \n\n   Test_RMSE   Test_R2  \n0   5.545463  0.338920  \n1   5.549810  0.337883  \n0   4.240279  0.613484  \n0   4.029500  0.650956  \n0   4.097010  0.639162  \n0   3.984024  0.658790  \n0   4.061587  0.645375  \n0   4.396792  0.584424  \n0   4.112081  0.636502  \n0   4.203455  0.620168  \n0   4.261240  0.609653  \n0   4.043927  0.648452  \n0   4.845861  0.495199  \n0   4.975756  0.467774  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>RandomForest</td>\n      <td>0.666268</td>\n      <td>0.054562</td>\n      <td>3.401824</td>\n      <td>4.097010</td>\n      <td>0.639162</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>RandomForest</td>\n      <td>0.655445</td>\n      <td>0.047001</td>\n      <td>3.328765</td>\n      <td>3.984024</td>\n      <td>0.658790</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>GradientBoosting</td>\n      <td>0.625801</td>\n      <td>0.083593</td>\n      <td>3.308267</td>\n      <td>4.061587</td>\n      <td>0.645375</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>GradientBoosting</td>\n      <td>0.600088</td>\n      <td>0.077933</td>\n      <td>3.501641</td>\n      <td>4.396792</td>\n      <td>0.584424</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>XGBoost</td>\n      <td>0.630576</td>\n      <td>0.074766</td>\n      <td>3.329362</td>\n      <td>4.112081</td>\n      <td>0.636502</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>XGBoost</td>\n      <td>0.587623</td>\n      <td>0.085667</td>\n      <td>3.304916</td>\n      <td>4.203455</td>\n      <td>0.620168</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>Ridge</td>\n      <td>0.689364</td>\n      <td>0.031347</td>\n      <td>3.329175</td>\n      <td>4.261240</td>\n      <td>0.609653</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>Ridge</td>\n      <td>0.698422</td>\n      <td>0.029387</td>\n      <td>3.259923</td>\n      <td>4.043927</td>\n      <td>0.648452</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>ElasticNet</td>\n      <td>0.605416</td>\n      <td>0.057165</td>\n      <td>4.075815</td>\n      <td>4.845861</td>\n      <td>0.495199</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>ElasticNet</td>\n      <td>0.570783</td>\n      <td>0.053047</td>\n      <td>4.120743</td>\n      <td>4.975756</td>\n      <td>0.467774</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":46},{"id":"7eb92ec3-3564-413b-ade7-d59700396e80","cell_type":"markdown","source":"On the other hand, the ElasticNet model is one of the least accurate models from all the models we have trained (but still better than the Decision Tree model). It has an error span of about 4% body fat in terms of its MAE and RMSE scores, which is still one of the higher values across the other MAE and RMSE scores in our dataframe.","metadata":{}},{"id":"6c871c5f-8deb-4615-a8d9-67c19da2bd40","cell_type":"markdown","source":"### 8. Support Vector Regression","metadata":{}},{"id":"9d9ed014-0560-496e-bfb4-82512b82de83","cell_type":"code","source":"all_results = pd.concat([\n    all_results,\n    evaluate_model(SVR(), 'SVR', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(SVR(), 'SVR', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:46:05.838569Z","iopub.execute_input":"2025-09-04T12:46:05.839234Z","iopub.status.idle":"2025-09-04T12:46:05.906573Z","shell.execute_reply.started":"2025-09-04T12:46:05.839205Z","shell.execute_reply":"2025-09-04T12:46:05.905763Z"}},"outputs":[],"execution_count":47},{"id":"7a2bf55f-8812-48fe-b33c-823c234b67be","cell_type":"code","source":"display(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:46:13.216508Z","iopub.execute_input":"2025-09-04T12:46:13.217163Z","iopub.status.idle":"2025-09-04T12:46:13.229397Z","shell.execute_reply.started":"2025-09-04T12:46:13.217135Z","shell.execute_reply":"2025-09-04T12:46:13.228489Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0       Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1  Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n0       Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n0  Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n0       Scaled-only      RandomForest    0.666268   0.054562  3.401824   \n0  Feature-Selected      RandomForest    0.655445   0.047001  3.328765   \n0       Scaled-only  GradientBoosting    0.625801   0.083593  3.308267   \n0  Feature-Selected  GradientBoosting    0.600088   0.077933  3.501641   \n0       Scaled-only           XGBoost    0.630576   0.074766  3.329362   \n0  Feature-Selected           XGBoost    0.587623   0.085667  3.304916   \n0       Scaled-only             Ridge    0.689364   0.031347  3.329175   \n0  Feature-Selected             Ridge    0.698422   0.029387  3.259923   \n0       Scaled-only        ElasticNet    0.605416   0.057165  4.075815   \n0  Feature-Selected        ElasticNet    0.570783   0.053047  4.120743   \n0       Scaled-only               SVR    0.508879   0.053317  4.199976   \n0  Feature-Selected               SVR    0.463301   0.067848  3.907628   \n\n   Test_RMSE   Test_R2  \n0   5.545463  0.338920  \n1   5.549810  0.337883  \n0   4.240279  0.613484  \n0   4.029500  0.650956  \n0   4.097010  0.639162  \n0   3.984024  0.658790  \n0   4.061587  0.645375  \n0   4.396792  0.584424  \n0   4.112081  0.636502  \n0   4.203455  0.620168  \n0   4.261240  0.609653  \n0   4.043927  0.648452  \n0   4.845861  0.495199  \n0   4.975756  0.467774  \n0   5.130864  0.434074  \n0   4.886839  0.486625  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>RandomForest</td>\n      <td>0.666268</td>\n      <td>0.054562</td>\n      <td>3.401824</td>\n      <td>4.097010</td>\n      <td>0.639162</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>RandomForest</td>\n      <td>0.655445</td>\n      <td>0.047001</td>\n      <td>3.328765</td>\n      <td>3.984024</td>\n      <td>0.658790</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>GradientBoosting</td>\n      <td>0.625801</td>\n      <td>0.083593</td>\n      <td>3.308267</td>\n      <td>4.061587</td>\n      <td>0.645375</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>GradientBoosting</td>\n      <td>0.600088</td>\n      <td>0.077933</td>\n      <td>3.501641</td>\n      <td>4.396792</td>\n      <td>0.584424</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>XGBoost</td>\n      <td>0.630576</td>\n      <td>0.074766</td>\n      <td>3.329362</td>\n      <td>4.112081</td>\n      <td>0.636502</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>XGBoost</td>\n      <td>0.587623</td>\n      <td>0.085667</td>\n      <td>3.304916</td>\n      <td>4.203455</td>\n      <td>0.620168</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>Ridge</td>\n      <td>0.689364</td>\n      <td>0.031347</td>\n      <td>3.329175</td>\n      <td>4.261240</td>\n      <td>0.609653</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>Ridge</td>\n      <td>0.698422</td>\n      <td>0.029387</td>\n      <td>3.259923</td>\n      <td>4.043927</td>\n      <td>0.648452</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>ElasticNet</td>\n      <td>0.605416</td>\n      <td>0.057165</td>\n      <td>4.075815</td>\n      <td>4.845861</td>\n      <td>0.495199</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>ElasticNet</td>\n      <td>0.570783</td>\n      <td>0.053047</td>\n      <td>4.120743</td>\n      <td>4.975756</td>\n      <td>0.467774</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>SVR</td>\n      <td>0.508879</td>\n      <td>0.053317</td>\n      <td>4.199976</td>\n      <td>5.130864</td>\n      <td>0.434074</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>SVR</td>\n      <td>0.463301</td>\n      <td>0.067848</td>\n      <td>3.907628</td>\n      <td>4.886839</td>\n      <td>0.486625</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":48},{"id":"499e0896-07c7-4f8b-bdf1-a3a19a8fcf26","cell_type":"markdown","source":"The Support Vector Regression model is about the same performance as what can be said about the ElasticNet model.","metadata":{}},{"id":"5a43ae61-643b-483f-a31f-63c9280a2f1f","cell_type":"markdown","source":"### 9. K-Nearest Neighbors Regressor","metadata":{}},{"id":"08576cc1-e169-4091-9222-0ebd06a88b35","cell_type":"code","source":"all_results = pd.concat([\n    all_results,\n    evaluate_model(KNeighborsRegressor(n_neighbors=5), 'KNRegressor', X_train_scaled, X_test_scaled, y_train, y_test, 'Scaled-only'),\n    evaluate_model(KNeighborsRegressor(n_neighbors=5), 'KNRegressor', X_train_fs, X_test_fs, y_train, y_test, 'Feature-Selected')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:50:07.704973Z","iopub.execute_input":"2025-09-04T12:50:07.705313Z","iopub.status.idle":"2025-09-04T12:50:07.754326Z","shell.execute_reply.started":"2025-09-04T12:50:07.705288Z","shell.execute_reply":"2025-09-04T12:50:07.753648Z"}},"outputs":[],"execution_count":49},{"id":"5c504469-9002-4871-a15f-0dff2d638b72","cell_type":"code","source":"display(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:50:17.356707Z","iopub.execute_input":"2025-09-04T12:50:17.357515Z","iopub.status.idle":"2025-09-04T12:50:17.369369Z","shell.execute_reply.started":"2025-09-04T12:50:17.357477Z","shell.execute_reply":"2025-09-04T12:50:17.368649Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"            Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0       Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1  Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n0       Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n0  Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n0       Scaled-only      RandomForest    0.666268   0.054562  3.401824   \n0  Feature-Selected      RandomForest    0.655445   0.047001  3.328765   \n0       Scaled-only  GradientBoosting    0.625801   0.083593  3.308267   \n0  Feature-Selected  GradientBoosting    0.600088   0.077933  3.501641   \n0       Scaled-only           XGBoost    0.630576   0.074766  3.329362   \n0  Feature-Selected           XGBoost    0.587623   0.085667  3.304916   \n0       Scaled-only             Ridge    0.689364   0.031347  3.329175   \n0  Feature-Selected             Ridge    0.698422   0.029387  3.259923   \n0       Scaled-only        ElasticNet    0.605416   0.057165  4.075815   \n0  Feature-Selected        ElasticNet    0.570783   0.053047  4.120743   \n0       Scaled-only               SVR    0.508879   0.053317  4.199976   \n0  Feature-Selected               SVR    0.463301   0.067848  3.907628   \n0       Scaled-only       KNRegressor    0.564583   0.073110  4.030980   \n0  Feature-Selected       KNRegressor    0.536755   0.079227  3.880000   \n\n   Test_RMSE   Test_R2  \n0   5.545463  0.338920  \n1   5.549810  0.337883  \n0   4.240279  0.613484  \n0   4.029500  0.650956  \n0   4.097010  0.639162  \n0   3.984024  0.658790  \n0   4.061587  0.645375  \n0   4.396792  0.584424  \n0   4.112081  0.636502  \n0   4.203455  0.620168  \n0   4.261240  0.609653  \n0   4.043927  0.648452  \n0   4.845861  0.495199  \n0   4.975756  0.467774  \n0   5.130864  0.434074  \n0   4.886839  0.486625  \n0   4.807285  0.503204  \n0   4.688168  0.527519  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>RandomForest</td>\n      <td>0.666268</td>\n      <td>0.054562</td>\n      <td>3.401824</td>\n      <td>4.097010</td>\n      <td>0.639162</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>RandomForest</td>\n      <td>0.655445</td>\n      <td>0.047001</td>\n      <td>3.328765</td>\n      <td>3.984024</td>\n      <td>0.658790</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>GradientBoosting</td>\n      <td>0.625801</td>\n      <td>0.083593</td>\n      <td>3.308267</td>\n      <td>4.061587</td>\n      <td>0.645375</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>GradientBoosting</td>\n      <td>0.600088</td>\n      <td>0.077933</td>\n      <td>3.501641</td>\n      <td>4.396792</td>\n      <td>0.584424</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>XGBoost</td>\n      <td>0.630576</td>\n      <td>0.074766</td>\n      <td>3.329362</td>\n      <td>4.112081</td>\n      <td>0.636502</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>XGBoost</td>\n      <td>0.587623</td>\n      <td>0.085667</td>\n      <td>3.304916</td>\n      <td>4.203455</td>\n      <td>0.620168</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>Ridge</td>\n      <td>0.689364</td>\n      <td>0.031347</td>\n      <td>3.329175</td>\n      <td>4.261240</td>\n      <td>0.609653</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>Ridge</td>\n      <td>0.698422</td>\n      <td>0.029387</td>\n      <td>3.259923</td>\n      <td>4.043927</td>\n      <td>0.648452</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>ElasticNet</td>\n      <td>0.605416</td>\n      <td>0.057165</td>\n      <td>4.075815</td>\n      <td>4.845861</td>\n      <td>0.495199</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>ElasticNet</td>\n      <td>0.570783</td>\n      <td>0.053047</td>\n      <td>4.120743</td>\n      <td>4.975756</td>\n      <td>0.467774</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>SVR</td>\n      <td>0.508879</td>\n      <td>0.053317</td>\n      <td>4.199976</td>\n      <td>5.130864</td>\n      <td>0.434074</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>SVR</td>\n      <td>0.463301</td>\n      <td>0.067848</td>\n      <td>3.907628</td>\n      <td>4.886839</td>\n      <td>0.486625</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>KNRegressor</td>\n      <td>0.564583</td>\n      <td>0.073110</td>\n      <td>4.030980</td>\n      <td>4.807285</td>\n      <td>0.503204</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Feature-Selected</td>\n      <td>KNRegressor</td>\n      <td>0.536755</td>\n      <td>0.079227</td>\n      <td>3.880000</td>\n      <td>4.688168</td>\n      <td>0.527519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":50},{"id":"fa5a141d-cc6b-45fa-9339-12968cba4987","cell_type":"markdown","source":"The same can be said about the KNeighborsRegressor model as with the previous two models (though it is one of the better performing ones from the final three we trained, yet it falls short of the other models we have trained.)","metadata":{}},{"id":"66d04911-d881-415a-8a9a-e7ac5b28cca1","cell_type":"code","source":"# Reset index for cleanliness\nall_results = all_results.reset_index(drop=True)\ndisplay(all_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:52:43.164849Z","iopub.execute_input":"2025-09-04T12:52:43.165189Z","iopub.status.idle":"2025-09-04T12:52:43.178624Z","shell.execute_reply.started":"2025-09-04T12:52:43.165166Z","shell.execute_reply":"2025-09-04T12:52:43.177903Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"             Dataset             Model  CV_R2_Mean  CV_R2_Std  Test_MAE  \\\n0        Scaled-only      DecisionTree    0.425027   0.109527  4.270588   \n1   Feature-Selected      DecisionTree    0.297680   0.115825  4.360784   \n2        Scaled-only  LinearRegression    0.686319   0.031946  3.329254   \n3   Feature-Selected  LinearRegression    0.695245   0.035255  3.248772   \n4        Scaled-only      RandomForest    0.666268   0.054562  3.401824   \n5   Feature-Selected      RandomForest    0.655445   0.047001  3.328765   \n6        Scaled-only  GradientBoosting    0.625801   0.083593  3.308267   \n7   Feature-Selected  GradientBoosting    0.600088   0.077933  3.501641   \n8        Scaled-only           XGBoost    0.630576   0.074766  3.329362   \n9   Feature-Selected           XGBoost    0.587623   0.085667  3.304916   \n10       Scaled-only             Ridge    0.689364   0.031347  3.329175   \n11  Feature-Selected             Ridge    0.698422   0.029387  3.259923   \n12       Scaled-only        ElasticNet    0.605416   0.057165  4.075815   \n13  Feature-Selected        ElasticNet    0.570783   0.053047  4.120743   \n14       Scaled-only               SVR    0.508879   0.053317  4.199976   \n15  Feature-Selected               SVR    0.463301   0.067848  3.907628   \n16       Scaled-only       KNRegressor    0.564583   0.073110  4.030980   \n17  Feature-Selected       KNRegressor    0.536755   0.079227  3.880000   \n\n    Test_RMSE   Test_R2  \n0    5.545463  0.338920  \n1    5.549810  0.337883  \n2    4.240279  0.613484  \n3    4.029500  0.650956  \n4    4.097010  0.639162  \n5    3.984024  0.658790  \n6    4.061587  0.645375  \n7    4.396792  0.584424  \n8    4.112081  0.636502  \n9    4.203455  0.620168  \n10   4.261240  0.609653  \n11   4.043927  0.648452  \n12   4.845861  0.495199  \n13   4.975756  0.467774  \n14   5.130864  0.434074  \n15   4.886839  0.486625  \n16   4.807285  0.503204  \n17   4.688168  0.527519  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Model</th>\n      <th>CV_R2_Mean</th>\n      <th>CV_R2_Std</th>\n      <th>Test_MAE</th>\n      <th>Test_RMSE</th>\n      <th>Test_R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scaled-only</td>\n      <td>DecisionTree</td>\n      <td>0.425027</td>\n      <td>0.109527</td>\n      <td>4.270588</td>\n      <td>5.545463</td>\n      <td>0.338920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feature-Selected</td>\n      <td>DecisionTree</td>\n      <td>0.297680</td>\n      <td>0.115825</td>\n      <td>4.360784</td>\n      <td>5.549810</td>\n      <td>0.337883</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Scaled-only</td>\n      <td>LinearRegression</td>\n      <td>0.686319</td>\n      <td>0.031946</td>\n      <td>3.329254</td>\n      <td>4.240279</td>\n      <td>0.613484</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Feature-Selected</td>\n      <td>LinearRegression</td>\n      <td>0.695245</td>\n      <td>0.035255</td>\n      <td>3.248772</td>\n      <td>4.029500</td>\n      <td>0.650956</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Scaled-only</td>\n      <td>RandomForest</td>\n      <td>0.666268</td>\n      <td>0.054562</td>\n      <td>3.401824</td>\n      <td>4.097010</td>\n      <td>0.639162</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Feature-Selected</td>\n      <td>RandomForest</td>\n      <td>0.655445</td>\n      <td>0.047001</td>\n      <td>3.328765</td>\n      <td>3.984024</td>\n      <td>0.658790</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Scaled-only</td>\n      <td>GradientBoosting</td>\n      <td>0.625801</td>\n      <td>0.083593</td>\n      <td>3.308267</td>\n      <td>4.061587</td>\n      <td>0.645375</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Feature-Selected</td>\n      <td>GradientBoosting</td>\n      <td>0.600088</td>\n      <td>0.077933</td>\n      <td>3.501641</td>\n      <td>4.396792</td>\n      <td>0.584424</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Scaled-only</td>\n      <td>XGBoost</td>\n      <td>0.630576</td>\n      <td>0.074766</td>\n      <td>3.329362</td>\n      <td>4.112081</td>\n      <td>0.636502</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Feature-Selected</td>\n      <td>XGBoost</td>\n      <td>0.587623</td>\n      <td>0.085667</td>\n      <td>3.304916</td>\n      <td>4.203455</td>\n      <td>0.620168</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Scaled-only</td>\n      <td>Ridge</td>\n      <td>0.689364</td>\n      <td>0.031347</td>\n      <td>3.329175</td>\n      <td>4.261240</td>\n      <td>0.609653</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Feature-Selected</td>\n      <td>Ridge</td>\n      <td>0.698422</td>\n      <td>0.029387</td>\n      <td>3.259923</td>\n      <td>4.043927</td>\n      <td>0.648452</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Scaled-only</td>\n      <td>ElasticNet</td>\n      <td>0.605416</td>\n      <td>0.057165</td>\n      <td>4.075815</td>\n      <td>4.845861</td>\n      <td>0.495199</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Feature-Selected</td>\n      <td>ElasticNet</td>\n      <td>0.570783</td>\n      <td>0.053047</td>\n      <td>4.120743</td>\n      <td>4.975756</td>\n      <td>0.467774</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Scaled-only</td>\n      <td>SVR</td>\n      <td>0.508879</td>\n      <td>0.053317</td>\n      <td>4.199976</td>\n      <td>5.130864</td>\n      <td>0.434074</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Feature-Selected</td>\n      <td>SVR</td>\n      <td>0.463301</td>\n      <td>0.067848</td>\n      <td>3.907628</td>\n      <td>4.886839</td>\n      <td>0.486625</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Scaled-only</td>\n      <td>KNRegressor</td>\n      <td>0.564583</td>\n      <td>0.073110</td>\n      <td>4.030980</td>\n      <td>4.807285</td>\n      <td>0.503204</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Feature-Selected</td>\n      <td>KNRegressor</td>\n      <td>0.536755</td>\n      <td>0.079227</td>\n      <td>3.880000</td>\n      <td>4.688168</td>\n      <td>0.527519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":51},{"id":"46b6c88b-801e-4315-ae01-c239d89c3401","cell_type":"code","source":"# Save metrics\nall_results.to_csv(\"/kaggle/working/model_comparison.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:56:05.503319Z","iopub.execute_input":"2025-09-04T12:56:05.504124Z","iopub.status.idle":"2025-09-04T12:56:05.509765Z","shell.execute_reply.started":"2025-09-04T12:56:05.504094Z","shell.execute_reply":"2025-09-04T12:56:05.508934Z"}},"outputs":[],"execution_count":53}]}